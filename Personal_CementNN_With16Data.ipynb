{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Personal_CementNN_With16Data.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shkailas/CementAnalysis/blob/main/Personal_CementNN_With16Data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQxN9ZOyoSSs"
      },
      "source": [
        "'''\n",
        "#\n",
        "#Mech-Chem UHPC.ipynb\n",
        "#Today\n",
        "#9:44 PM\n",
        "\n",
        "#You renamed an item\n",
        "#Text\n",
        "#Mech-Chem UHPC.ipynb\n",
        "#Mech-Chem UHPC.py\n",
        "#9:42 PM\n",
        "\n",
        "#You uploaded an item\n",
        "#Text\n",
        "Mech-Chem UHPC.py\n",
        "\"\"\"\n",
        "UHPC Neural Network for Intensity of Al, Ca, Fe, and Si to predcit nanoindentation M and H\n",
        "Created on Mon Nov  4 15:08:20 2019\n",
        "\n",
        "Emily Ford\n",
        "\"\"\"\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wVF-Jo57oEpe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83
        },
        "outputId": "6aae3a90-14f7-4286-fcd6-9a47cdbd7e57"
      },
      "source": [
        "# %% Preliminaries\n",
        "\n",
        "from __future__ import absolute_import, division, print_function  # Python 2/3 compatibility\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
        "from sklearn.metrics import confusion_matrix, mean_squared_error, mean_absolute_error\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "# %% Import Keras objects for Deep Learning\n",
        "\n",
        "from keras.models  import Sequential, K\n",
        "from keras.layers import Input, Dense, Flatten, Dropout, BatchNormalization\n",
        "from keras.optimizers import Adam, SGD, RMSprop"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mkf7PsTnogW5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 872
        },
        "outputId": "d485c87e-6179-428f-c666-1214ba7759d4"
      },
      "source": [
        "# %% Load in the data set F28 to Train Model\n",
        "# Import the data using the file path\n",
        "\n",
        "#filepath = '/content/drive/My Drive/Fish_Length.csv'\n",
        "\n",
        "#filepath = '/content/drive/My Drive/Copy of _F28 Combo.xlsx'\n",
        "filepath = \"/content/_F28 Adj 1 extra.xlsx\"\n",
        "names=['','H','M','Al','Ca','Fe','Si']\n",
        "\n",
        "df = pd.read_excel(filepath, header = 0)\n",
        "\n",
        "\n",
        "#df = pd.read_excel (r'C:\\Users\\pinka\\Documents\\Doctoral Thesis\\Data Analysis\\Machine Learning\\_F28 Combo.xlsx',header=0) #Import .xlsx file\n",
        "print('\\n')\n",
        "print(df.shape)\n",
        "df.sample(5)\n",
        "\n",
        "# %% Data Variables\n",
        "X = df.iloc[:, 18:18+46].values # All rows, Third to 276th Column (IAl, ICa, IFe, ISi)\n",
        "Y = df.iloc[:,1:2].values  # All rows, First and Second column (H and M)\n",
        "\n",
        "print('\\n')\n",
        "print('Sample of X Data \\n')\n",
        "print(X[0:9]) # Confirm data was sucessfully assigned\n",
        "print('\\n')\n",
        "print('Sample of Y Data \\n')\n",
        "print(Y[0:9]) # Confirm data was sucessfully assigned\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "(1181, 55)\n",
            "\n",
            "\n",
            "Sample of X Data \n",
            "\n",
            "[[ 13 240  24 144  21 191  45  93  16 182  25 108  22 161  39  97   9 226\n",
            "   45 121  15 239  23 144  12 226  78 121  16 224  40 139  22 230  39 164\n",
            "   30]\n",
            " [ 16 224  40 139   9 226  45 121  13 240  24 144  15 239  23 144  12 226\n",
            "   78 121  22 230  39 164  18 226  56 117  13 233  39 169  23 232  36 135\n",
            "   30]\n",
            " [ 13 233  39 169  12 226  78 121  16 224  40 139  22 230  39 164  18 226\n",
            "   56 117  23 232  36 135  35 229  89 114  14 238  46 167  17 230  38 151\n",
            "   30]\n",
            " [ 14 238  46 167  18 226  56 117  13 233  39 169  23 232  36 135  35 229\n",
            "   89 114  17 230  38 151  33 169  66  84  19 201  59  89  70 162 102  94\n",
            "   30]\n",
            " [ 29 161  32  81  33 169  66  84  19 201  59  89  70 162 102  94  29 167\n",
            "   23  83  45 113  48 156  34 164  72  58  68 171  65  57  19 146  75  69\n",
            "   30]\n",
            " [ 68 171  65  57  29 167  23  83  29 161  32  81  45 113  48 156  34 164\n",
            "   72  58  19 146  75  69  24 173  43  70  34 178  41  94  33 120  52 104\n",
            "   30]\n",
            " [ 34 178  41  94  34 164  72  58  68 171  65  57  19 146  75  69  24 173\n",
            "   43  70  33 120  52 104  16 142  31  80  18 171  38  87  23 134  42  74\n",
            "   30]\n",
            " [ 18 171  38  87  24 173  43  70  34 178  41  94  33 120  52 104  16 142\n",
            "   31  80  23 134  42  74  25 159  28  66  14 159  48  50  17 119  30  47\n",
            "   30]\n",
            " [ 14 159  48  50  16 142  31  80  18 171  38  87  23 134  42  74  25 159\n",
            "   28  66  17 119  30  47  20 163  43  87  21 138  52  78  16 155  22  77\n",
            "   30]]\n",
            "\n",
            "\n",
            "Sample of Y Data \n",
            "\n",
            "[[ 85.639]\n",
            " [131.82 ]\n",
            " [132.27 ]\n",
            " [139.28 ]\n",
            " [ 45.554]\n",
            " [ 45.873]\n",
            " [ 43.162]\n",
            " [ 45.489]\n",
            " [ 32.435]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KoZSeV-6p46u",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "57d60742-9d33-477d-9791-2d6b20e0fac8"
      },
      "source": [
        "# Split the data to Train, and Test (75%, 25%)\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.01, random_state=452452246)\n",
        "\n",
        "# %% Data is normalized to aid the training of neural nets by providing numerical stability\n",
        "normalizer = StandardScaler()\n",
        "\n",
        "X_train_norm =normalizer.fit_transform(X_train) # Re-center data at 0,0 by (x-mean)/std dev\n",
        "X_test_norm = normalizer.fit_transform(X_test)\n",
        "\n",
        "#Shankar: Normalized Y data\n",
        "Y_train_norm =normalizer.fit_transform(Y_train) # Re-center data at 0,0 by (y-mean)/std dev\n",
        "Y_test_norm = normalizer.fit_transform(Y_test)\n",
        "\n",
        "print(X_train.std)\n",
        "\n",
        "print(X_train.mean)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<built-in method std of numpy.ndarray object at 0x7fb9910ccd00>\n",
            "<built-in method mean of numpy.ndarray object at 0x7fb9910ccd00>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F1BkGQRPgiZj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        },
        "outputId": "79786438-6561-41ba-f344-3dc96f7c3eba"
      },
      "source": [
        "#Linear Regression Model\n",
        "from sklearn.linear_model import LinearRegression\n",
        "lin_reg = LinearRegression()\n",
        "lin_reg.fit(X_train_norm,Y_train_norm)\n",
        "#print(lin_reg.intercept_)\n",
        "print('\\n\\n\\n')\n",
        "#print(lin_reg.coef_ )\n",
        "print('\\n\\n\\n')\n",
        "\n",
        "print('mse of lin reg')\n",
        "Y_val_predict_norm = lin_reg.predict(X_test_norm)\n",
        "print(mean_squared_error(Y_test_norm,Y_val_predict_norm))\n",
        "\n",
        "#function to plot scatter\n",
        "def plot_Scatter(x1,y1,y1pred,xLab,yLab):\n",
        "  plt.figure(1)\n",
        "\n",
        "  plt.scatter(x1, y1, color='red',label='Test Data') # \n",
        "  plt.scatter(x1, y1pred, color='cyan',label='Model Results of Test Data') # \n",
        "  plt.xlabel(xLab)\n",
        "  plt.ylabel(yLab)\n",
        "  plt.legend(loc=\"upper left\")\n",
        "  plt.show()\n",
        "\n",
        "#print(\"H vs each input element\")\n",
        "#H vs each input element\n",
        "#plot_Scatter(X_test_norm[:,0],Y_test_norm[:,0],Y_val_predict_norm[:,0],\"I_Al\",\"H\") \n",
        "#plot_Scatter(X_test_norm[:,1],Y_test_norm[:,0],Y_val_predict_norm[:,0],\"I_Ca\",\"H\") \n",
        "#plot_Scatter(X_test_norm[:,2],Y_test_norm[:,0],Y_val_predict_norm[:,0],\"I_Fe\",\"H\") \n",
        "#plot_Scatter(X_test_norm[:,3],Y_test_norm[:,0],Y_val_predict_norm[:,0],\"I_Si\",\"H\") \n",
        "\n",
        "#print('M vs each input element')\n",
        "\n",
        "#M vs each input element\n",
        "#plot_Scatter(X_test_norm[:,0],Y_test_norm[:,1],Y_val_predict_norm[:,1],\"I_Al\",\"M\") \n",
        "#plot_Scatter(X_test_norm[:,1],Y_test_norm[:,1],Y_val_predict_norm[:,1],\"I_Ca\",\"M\") \n",
        "#plot_Scatter(X_test_norm[:,2],Y_test_norm[:,1],Y_val_predict_norm[:,1],\"I_Fe\",\"M\") \n",
        "#plot_Scatter(X_test_norm[:,3],Y_test_norm[:,1],Y_val_predict_norm[:,1],\"I_Si\",\"M\") "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "mse of lin reg\n",
            "0.4292712226148457\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2cPN7nN0w9ug",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        },
        "outputId": "8c0e2815-8dca-4167-a334-54396c4f2473"
      },
      "source": [
        "#Polynomial Regression Model Degree 2(Shankar)\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "poly_features = PolynomialFeatures(degree=3, interaction_only = True, include_bias = False)\n",
        "X_poly_train_norm = poly_features.fit_transform(X_train_norm)\n",
        "X_poly_test_norm = poly_features.fit_transform(X_test_norm)\n",
        "\n",
        "lin_poly_reg = LinearRegression()\n",
        "lin_poly_reg.fit(X_poly_train_norm,Y_train_norm)\n",
        "#print(lin_poly_reg.intercept_)\n",
        "print('\\n\\n\\n')\n",
        "#print(lin_poly_reg.coef_ )\n",
        "print('\\n\\n\\n')\n",
        "Y_poly_predict_norm = lin_poly_reg.predict(X_poly_train_norm)\n",
        "Y_poly_test_predict_norm = lin_poly_reg.predict(X_poly_test_norm)\n",
        "\n",
        "\n",
        "print(mean_squared_error(Y_test_norm,Y_poly_test_predict_norm))\n",
        "#plt.figure(1)\n",
        "#plt.scatter(Y_train_norm[:,0], Y_poly_predict_norm[:,0], color='red',label='Train Data')\n",
        "#plt.xlabel(\"Hpred\")\n",
        "#plt.ylabel(\"Hactual\")\n",
        "#plt.show\n",
        "\n",
        "#plt.figure(2)\n",
        "#plt.scatter(Y_train_norm[:,1], Y_poly_predict_norm[:,1], color='blue',label='Train Data')\n",
        "#plt.xlabel(\"Mpred\")\n",
        "#plt.ylabel(\"Mactual\")\n",
        "#plt.show\n",
        "\n",
        "#plt.figure(3)\n",
        "#plt.scatter(Y_test_norm[:,0], Y_poly_test_predict_norm[:,0], color='green',label='Train Data')\n",
        "#plt.xlabel(\"Hpred\")\n",
        "#plt.ylabel(\"Hactual\")\n",
        "#plt.show\n",
        "#Loop for H plots\n",
        "##for(i in ):\n",
        "###  plot_Scatter(X_test_norm[:,0],Y_test_norm[:,1],Y_val_predict_norm[:,1],\"I_Al\",\"M\") \n",
        "\n",
        "#Loop for M plots\n",
        "##for(i in ):\n",
        "###  plot_Scatter(X_test_norm[:,0],Y_test_norm[:,1],Y_val_predict_norm[:,1],\"I_Al\",\"M\") "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "1.5716832639134202\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KcxbCVxbjxf6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "b2e14cae-83b2-4048-9cb0-89769946c609"
      },
      "source": [
        "print(mean_squared_error(Y_train_norm[:,0], Y_poly_predict_norm[:,0]))\n",
        "print(mean_squared_error(Y_train_norm[:,1], Y_poly_predict_norm[:,1]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9.207663293137878e-30\n",
            "8.164681491662405e-30\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z7VOkX4nGfSf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "06806931-6721-467f-e6ae-a0422f682b83"
      },
      "source": [
        "#KNN Regression(Shankar)\n",
        "import sklearn.neighbors\n",
        "knn_reg = sklearn.neighbors.KNeighborsRegressor(n_neighbors = 3)\n",
        "knn_reg.fit(X_train_norm,Y_train_norm[:,0])\n",
        "Y_knn_predict = knn_reg.predict(X_test_norm)\n",
        "print(\"old:\")\n",
        "print( mean_squared_error(Y_test_norm[:,0],Y_knn_predict))\n",
        "\n",
        "#n_neighbors=5, radius=1.0, algorithm='auto', leaf_size=30, metric='minkowski', p=2, metric_params=None, n_jobs=None\n",
        "# Applying Grid Search to KNN Reg(Shankar)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "old:\n",
            "0.7818253064118922\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iN8v-IPOC0QQ"
      },
      "source": [
        "# Applying Grid Search to find the best model and the best parameters(Shankar)\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import mean_squared_error\n",
        "Y_svm_predict = svm_linear_reg_H.predict(X_test_norm)\n",
        "\n",
        "parameters = [{'C': [1, 10, 100, 1000], 'kernel': ['linear']},\n",
        "              {'C': [1, 10, 100, 1000], 'kernel': ['rbf'], 'gamma': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]}]\n",
        "\n",
        "grid_search = GridSearchCV(estimator = svm_linear_reg_H,\n",
        "                           param_grid = parameters,\n",
        "                           \n",
        "                           cv = 10,\n",
        "                           n_jobs = -1)\n",
        "grid_search = grid_search.fit(X_train_norm, Y_train_norm[:,0])\n",
        "\n",
        "rsq = grid_search.best_score_\n",
        "print(rsq)\n",
        "grid_search.best_params_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_zK2W6Gm1xO"
      },
      "source": [
        "#knn with new parameters\n",
        "print('new params knn')\n",
        "knn_reg = sklearn.neighbors.KNeighborsRegressor(n_neighbors = 10,p=2,metric='minkowski')\n",
        "knn_reg.fit(X_train_norm,Y_train_norm[:,0])\n",
        "Y_knn_predict = knn_reg.predict(X_test_norm)\n",
        "mean_squared_error(Y_test_norm[:,0],Y_knn_predict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WXq4uCgHHp2-"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8avcikc1HpzU"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eRcPfhTYHpwo"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EljUYDCTp0CA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b6d87da9-b603-47ce-8330-2decc168b723"
      },
      "source": [
        "#SVM Linear Regression(Shankar)\n",
        "from sklearn.svm import LinearSVR\n",
        "from sklearn.svm import SVR\n",
        "\n",
        "svm_linear_reg_H = SVR(kernel = 'rbf', C=1.0, epsilon = 0.5)\n",
        "svm_linear_reg_M = LinearSVR(epsilon = .5)\n",
        "\n",
        "svm_linear_reg_M.fit(X_train_norm,Y_train_norm)\n",
        "Y_predict_norm = svm_linear_reg_M.predict(X_test_norm)\n",
        "mean_squared_error(Y_test_norm,Y_predict_norm)\n",
        "#svm_linear_reg_H.score(X_test_norm, Y_test_norm[:,0], sample_weight=None)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4262284518275626"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DwMUobm-Piam"
      },
      "source": [
        "# Applying Grid Search to find the best model and the best parameters(Shankar)\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import mean_squared_error\n",
        "Y_svm_predict = svm_linear_reg_H.predict(X_test_norm)\n",
        "\n",
        "parameters = [{'C': [1, 10, 100, 1000], 'kernel': ['linear']},\n",
        "              {'C': [1, 10, 100, 1000], 'kernel': ['rbf'], 'gamma': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]}]\n",
        "\n",
        "grid_search = GridSearchCV(estimator = svm_linear_reg_H,\n",
        "                           param_grid = parameters,\n",
        "                           \n",
        "                           cv = 10,\n",
        "                           n_jobs = -1)\n",
        "grid_search = grid_search.fit(X_train_norm, Y_train_norm[:,0])\n",
        "\n",
        "rsq = grid_search.best_score_\n",
        "print(rsq)\n",
        "grid_search.best_params_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89PHLzFcWLTv"
      },
      "source": [
        "svm_linear_reg_H = SVR(kernel = 'linear', C=10)\n",
        "svm_linear_reg_H.fit(X_train_norm,Y_train_norm[:,0])\n",
        "Y_svm_predict = svm_linear_reg_H.predict(X_test_norm)\n",
        "svm_linear_reg_H.score(X_test_norm, Y_test_norm[:,0], sample_weight=None)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JnGAhojbslTt"
      },
      "source": [
        "# %% Define the Model \n",
        "'''\n",
        "Build a Single Hidden Layer Neural Network\n",
        "We will use the Sequential model to quickly build a neural network. \n",
        "Our first network will be a single layer network. \n",
        "We have 4 variables, so we set the input shape to 4. \n",
        "'''\n",
        "## Past Run History\n",
        "# Dense 6, Dense 2 w/200 Epochs MSE = 154.814 MAE = 6.827  F28\n",
        "# Dense 6, Dense 2 w/400 Epochs MSE = 153.340 MAE = 6.796  F28\n",
        "# Dense 6, Dense 2 w/400 Epochs MSE = 445.224 MAE = 11.433 F90\n",
        "\n",
        "# Dense 8, Dense 2 w/200 Epochs MSE = 150.260 MAE = 6.737  F28\n",
        "# Dense 8, Dense 2 w/200 Epochs MSE = 421.807 MAE = 11.282 F90\n",
        "\n",
        "model_1 = Sequential([\n",
        "    Dense(8, input_shape=(16,), activation=\"relu\"),\n",
        "    Dense(2) # No activation function for output later since regression problem and we want numerical values without transform\n",
        "    ])\n",
        "\n",
        "#  View the model and count the parameters\n",
        "model_1.summary()\n",
        "\n",
        "# %% Fit(Train) the Model\n",
        "\n",
        "# Compile the model with Optimizer, Loss Function and Metrics\n",
        "model_1.compile(RMSprop(lr = .003), loss=\"mean_squared_error\",  metrics=['mae', 'mse']) # Regression\n",
        "run_hist_1 = model_1.fit(X_train_norm, Y_train_norm, validation_data=(X_test_norm, Y_test_norm), epochs=200)\n",
        "# Fit function returns the run history. \n",
        "# Contains information about the model fit, iterations etc.\n",
        "\n",
        "# %% Generate an H and M prediction from the model\n",
        "Y_pred_test_norm = model_1.predict(X_test_norm)\n",
        "\n",
        "# Check out the outputs\n",
        "print('Sample of Predicted Test Y Data \\n')\n",
        "print(Y_pred_test_norm[:10],Y_test_norm[:10])\n",
        "\n",
        "# %% Print model performance and plot the data comparison\n",
        "print(\"\\n\")\n",
        "print('Mean Square Error is {:.3f}'.format(mean_squared_error(Y_test_norm,Y_pred_test_norm))) # Regression Metric\n",
        "print('Mean Absolute Error is {:.3f}'.format(mean_absolute_error(Y_test_norm,Y_pred_test_norm))) # Regression Metric\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CBmlhNBlWI0k"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Gu3LNWKoVE-"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "plt.figure(1)\n",
        "\n",
        "plt.scatter(X_test_norm[:,1], Y_test_norm[:,0], color='red',label='Test Data') # Ca vs. Hardness Test Data\n",
        "plt.scatter(X_test_norm[:,1], Y_pred_test_norm[:,0], color='cyan',label='Model Results of Test Data') # Ca vs. Hardness Predicted Data\n",
        "plt.xlabel('I_Ca')\n",
        "plt.ylabel('H')\n",
        "plt.legend(loc=\"upper left\")\n",
        "plt.show()\n",
        "\n",
        "plt.figure(2)\n",
        "plt.scatter(X_test_norm[:,1], Y_test_norm[:,1], color='orange',label='Test Data') # Ca vs. M Test Data\n",
        "plt.scatter(X_test_norm[:,1], Y_pred_test_norm[:,1], color='blue',label='Model Results of Test Data') # Ca vs. M Predicted Data\n",
        "plt.xlabel('I_Ca')\n",
        "plt.ylabel('M')\n",
        "plt.legend(loc=\"upper left\")\n",
        "plt.show()\n",
        "\n",
        "# %% Plot Loss for Training and Validation Data Set\n",
        "run_hist_1.history.keys()\n",
        "fig, ax = plt.subplots()\n",
        "ax.plot(run_hist_1.history[\"loss\"],'r', marker='.', label=\"Train Loss\")\n",
        "ax.plot(run_hist_1.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss\")\n",
        "ax.legend()\n",
        "\n",
        "# Zoomed In \n",
        "fig, ax = plt.subplots()\n",
        "ax.set_ylim(125, 170)\n",
        "ax.plot(run_hist_1.history[\"loss\"],'r', marker='.', label=\"Train Loss\")\n",
        "ax.plot(run_hist_1.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss\")\n",
        "ax.legend()\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ntu4bo7o77eS"
      },
      "source": [
        "#Shankar(Linear actual vs Pred for neural net)\n",
        "plt.figure(1)\n",
        "plt.scatter(Y_test_norm[:,0], Y_pred_test_norm[:,0], color='red',label='Train Data')\n",
        "plt.xlabel(\"Hpred\")\n",
        "plt.ylabel(\"Hactual\")\n",
        "plt.show\n",
        "\n",
        "plt.figure(2)\n",
        "plt.scatter(Y_test_norm[:,1], Y_pred_test_norm[:,1], color='blue',label='Train Data')\n",
        "plt.xlabel(\"Mpred\")\n",
        "plt.ylabel(\"Mactual\")\n",
        "plt.show"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MjC88rHEvZ-A"
      },
      "source": [
        "# %% Run Additional Epochs\n",
        "# Note that when we call \"fit\" again, it picks up where it left off\n",
        "run_hist_1b = model_1.fit(X_train_norm, Y_train, validation_data=(X_test_norm, Y_test), epochs=500) # Run an additional epochs\n",
        "Y_pred_testb = model_1.predict(X_test)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SpXZY9pDviHc"
      },
      "source": [
        "# %% Plot Model Loss Results After Additional Epochs\n",
        "print(\"\\n\")\n",
        "print('Mean Square Error is {:.3f}'.format(mean_squared_error(Y_test_norm,Y_pred_test_norm))) # Regression Metric\n",
        "print('Mean Absolute Error is {:.3f}'.format(mean_absolute_error(Y_test_norm,Y_pred_test_norm))) # Regression Metric\n",
        "\n",
        "n = len(run_hist_1.history[\"loss\"])\n",
        "m = len(run_hist_1b.history['loss'])\n",
        "fig, ax = plt.subplots(figsize=(16, 8))\n",
        "#125 and 170\n",
        "ax.set_ylim(0, 10)\n",
        "ax.plot(range(n), run_hist_1.history[\"loss\"],'r', marker='.', label=\"Train Loss - Run 1\")\n",
        "ax.plot(range(n, n+m), run_hist_1b.history[\"loss\"], 'hotpink', marker='.', label=\"Train Loss - Run 2\")\n",
        "\n",
        "ax.plot(range(n), run_hist_1.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss - Run 1\")\n",
        "ax.plot(range(n, n+m), run_hist_1b.history[\"val_loss\"], 'LightSkyBlue', marker='.',  label=\"Validation Loss - Run 2\")\n",
        "\n",
        "ax.legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mh31GrGBsu3z"
      },
      "source": [
        "#%% Additional F90 Data for Prediction Same Model\n",
        "df2 = pd.read_excel ('_F90 Combo.xlsx',header=0) #Import .xlsx file 2\n",
        "print('\\n')\n",
        "print(df2.shape)\n",
        "df2.sample(5)\n",
        "\n",
        "X_test2 = df2.iloc[:, 2:6].values # All rows, Third to Sixth Column\n",
        "Y_test2 = df2.iloc[:,0:2].values  # All rows, First and Second column\n",
        "\n",
        "print('\\n')\n",
        "print(X_test2[0:9]) # Confirm data was sucessfully assigned\n",
        "print('\\n')\n",
        "print(Y_test2[0:9]) # Confirm data was sucessfully assigned\n",
        "\n",
        "## Data is normalized to aid the input of neural nets by providing numerical stability\n",
        "X_test2_norm = normalizer.fit_transform(X_test2)\n",
        "\n",
        "Y_pred_test2 = model_1.predict(X_test2_norm)\n",
        "\n",
        "#%% Results of F90 with model\n",
        "print(\"\\n\")\n",
        "print('Mean Square Error is {:.3f}'.format(mean_squared_error(Y_test2,Y_pred_test2))) # Regression Metric\n",
        "print('Mean Absolute Error is {:.3f}'.format(mean_absolute_error(Y_test2,Y_pred_test2))) # Regression Metric\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9rr2pQ80sqPF"
      },
      "source": [
        "\n",
        "plt.figure(3)\n",
        "\n",
        "plt.scatter(X_test2_norm[:,1], Y_test2[:,0], color='red',label='Test Data') # Ca vs. Hardness Test Data\n",
        "plt.scatter(X_test2_norm[:,1], Y_pred_test2[:,0], color='cyan',label='Model Results of Test Data') # Ca vs. Hardness Predicted Data\n",
        "plt.xlabel('I_Ca')\n",
        "plt.ylabel('H')\n",
        "plt.legend(loc=\"upper left\")\n",
        "plt.show()\n",
        "\n",
        "plt.figure(4)\n",
        "plt.scatter(X_test2_norm[:,1], Y_test2[:,1], color='orange',label='Test Data') # Ca vs. M Test Data\n",
        "plt.scatter(X_test2_norm[:,1], Y_pred_test2[:,1], color='blue',label='Model Results of Test Data') # Ca vs. M Predicted Data\n",
        "plt.xlabel('I_Ca')\n",
        "plt.ylabel('M')\n",
        "plt.legend(loc=\"upper left\")\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# %%"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MK917O5hogDO"
      },
      "source": [
        "this is a comment"
      ]
    }
  ]
}